{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SuperBot Vertex LangGraph Walkthrough\n",
        "\n",
        "This notebook demonstrates the SuperBot chatbot implemented with LangGraph and Google Vertex AI. You will load environment settings, inspect the reducer-backed state schema, compile the single-node graph, and compare invoke vs. streaming behaviors (`updates` vs. `values`).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Environment Setup\n",
        "- Ensure Google Cloud Application Default Credentials (ADC) are configured (`gcloud auth application-default login`).\n",
        "- Copy `configs/superbot.env.example` to `.env` (or supply your own env file) and fill in project, region, and model settings.\n",
        "- Install dependencies from `requirements.txt` so `langgraph` and `langchain-google-vertexai` are available.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables (falls back to .env if no path supplied)\n",
        "dotenv_loaded = load_dotenv()\n",
        "print(f\"dotenv loaded: {dotenv_loaded}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Inspect the LangGraph State\n",
        "The agent preserves conversation history in a reducer-managed list. The schema uses `typing.Annotated[..., add_messages]` so LangGraph appends new messages instead of replacing the state.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import get_type_hints\n",
        "\n",
        "from super_bot_agent.state import State\n",
        "\n",
        "# Display the reducer-backed type hints for the state schema\n",
        "state_annotations = get_type_hints(State, include_extras=True)\n",
        "state_annotations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Configure the Vertex Provider\n",
        "`VertexConfig` validates environment variables and feeds them into `ChatVertexAI`. The helper surfaces descriptive errors when keys are missing or malformed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from super_bot_agent.provider import VertexConfig\n",
        "\n",
        "try:\n",
        "    vertex_config = VertexConfig.from_env()\n",
        "    vertex_config\n",
        "except Exception as exc:  # noqa: BLE001 - display errors during setup\n",
        "    print(f\"Configuration error: {exc}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Compile the SuperBot Graph\n",
        "With a valid configuration you can materialize the single-node LangGraph workflow. The helper returns a compiled graph ready for `invoke` or `stream` operations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from super_bot_agent import build_super_bot_graph, build_vertex_chat_model\n",
        "\n",
        "try:\n",
        "    llm = build_vertex_chat_model()\n",
        "    graph = build_super_bot_graph(llm)\n",
        "    graph\n",
        "except Exception as exc:  # noqa: BLE001\n",
        "    print(f\"Graph initialization failed: {exc}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualize the Topology\n",
        "For quick introspection LangGraph can render a text diagram of the compiled workflow.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if \"graph\" in globals():\n",
        "    try:\n",
        "        graph.get_graph().print_ascii()\n",
        "    except AttributeError as exc:\n",
        "        print(f\"Graph visualization unavailable in this LangGraph version: {exc}\")\n",
        "else:\n",
        "    print(\"Graph is not initialized yet.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Run an Invoke Turn\n",
        "Invoke executes the graph synchronously and returns the accumulated state (human + assistant messages).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "\n",
        "def render_messages(messages):\n",
        "    for message in messages:\n",
        "        content = message.content\n",
        "        if isinstance(content, list):\n",
        "            fragments = []\n",
        "            for part in content:\n",
        "                if isinstance(part, dict) and isinstance(part.get(\"text\"), str):\n",
        "                    fragments.append(part[\"text\"])\n",
        "                elif isinstance(part, str):\n",
        "                    fragments.append(part)\n",
        "            content = \"\".join(fragments)\n",
        "        print(f\"[{message.type}] {content}\")\n",
        "\n",
        "\n",
        "payload = {\"messages\": [HumanMessage(content=\"Hi SuperBot, what can you help me with?\")]}\n",
        "\n",
        "if \"graph\" in globals():\n",
        "    invoke_result = graph.invoke(payload)\n",
        "    render_messages(invoke_result[\"messages\"])\n",
        "else:\n",
        "    print(\"Graph is not initialized yet.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Streaming Modes\n",
        "`graph.stream` exposes two educational perspectives:\n",
        "- `updates`: incremental deltas emitted as soon as the node yields output.\n",
        "- `values`: snapshots of the node state showing message accumulation at each stage.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "updates_payload = {\"messages\": [HumanMessage(content=\"Summarize the philosophy behind LangGraph reducers.\")]}\n",
        "\n",
        "if \"graph\" in globals():\n",
        "    print(\"--- Streaming (updates) ---\")\n",
        "    for event in graph.stream(updates_payload, stream_mode=\"updates\"):\n",
        "        print(event)\n",
        "else:\n",
        "    print(\"Graph is not initialized yet.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "values_payload = {\"messages\": [HumanMessage(content=\"Explain how SuperBot keeps track of prior conversational turns.\")]}\n",
        "\n",
        "if \"graph\" in globals():\n",
        "    print(\"--- Streaming (values) ---\")\n",
        "    for snapshot in graph.stream(values_payload, stream_mode=\"values\"):\n",
        "        node_state = snapshot.get(\"super_bot\", {})\n",
        "        render_messages(node_state.get(\"messages\", []))\n",
        "        print(\"---\")\n",
        "else:\n",
        "    print(\"Graph is not initialized yet.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Next Steps\n",
        "- Wrap this graph with LangServe or FastAPI to expose a web UI.\n",
        "- Experiment with different Vertex models by editing `VERTEX_MODEL` in your environment.\n",
        "- Extend the graph with additional nodes (planner, toolformer) once you are comfortable with the single-node reducer pattern.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
